(window.webpackJsonp=window.webpackJsonp||[]).push([[76],{979:function(s,t,a){"use strict";a.r(t);var e=a(6),r=Object(e.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"pg基础问题及处理方法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#pg基础问题及处理方法"}},[s._v("#")]),s._v(" PG基础问题及处理方法")]),s._v(" "),t("h1",{attrs:{id:"_1、pg中如何判断-idle-in-transaction-为僵尸事务"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1、pg中如何判断-idle-in-transaction-为僵尸事务"}},[s._v("#")]),s._v(" 1、PG中如何判断 idle in transaction 为僵尸事务")]),s._v(" "),t("p",[s._v("backend_xid：用来表示会话是否申请了事务号")]),s._v(" "),t("p",[s._v("backend_xmin：事务会话的快照ID")]),s._v(" "),t("p",[s._v("如果backend_xid 和 backend_xmin 为空，可清理掉该进程， 如果不为空，说明事务还没结束，如未提交")]),s._v(" "),t("h1",{attrs:{id:"_2、查看当前事务"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2、查看当前事务"}},[s._v("#")]),s._v(" 2、查看当前事务")]),s._v(" "),t("p",[s._v("select txid_current();")]),s._v(" "),t("h1",{attrs:{id:"_3、pg等待事件根因分析表"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3、pg等待事件根因分析表"}},[s._v("#")]),s._v(" 3、PG等待事件根因分析表")]),s._v(" "),t("p",[s._v("https://pgfans.cn/a/1654")]),s._v(" "),t("h1",{attrs:{id:"_4、autovacuum优化的小技巧"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4、autovacuum优化的小技巧"}},[s._v("#")]),s._v(" 4、AUTOVACUUM优化的小技巧")]),s._v(" "),t("p",[s._v("三个基本参数：\nautovacuum_max_workers：")]),s._v(" "),t("p",[s._v("工作进程数数量默认为3，增加 autovacuum worker的数量意味着更多的进程可用于清理数据，通常应该将worker的数量设置为3-cpu_count之间最先设置为CPU_COUNT的1/2吧，如果在系统高峰期，CPU资源出现了瓶颈，那么适当缩小该值，如果CPU资源还很充足，但是autovacuum的性能不足，那么就增加这个值。")]),s._v(" "),t("p",[s._v("maintenance_work_mem：")]),s._v(" "),t("p",[s._v("值越大，vacuum的效率越高，设置的太大耗尽了内存，会产生严重的性能问题")]),s._v(" "),t("p",[s._v("物理内存充足，建议maintenance_work_mem至少设置为 1 GB")]),s._v(" "),t("p",[s._v("1 GB的维护工作内存足以一次处理大约 1.79 亿个死元组")]),s._v(" "),t("p",[s._v("autovacuum_freeze_max_age：")]),s._v(" "),t("p",[s._v("减少 TXID 回绕的机会，越大，autovacuum运行的频率就越低，延迟太久会消耗txid编号")]),s._v(" "),t("p",[t("strong",[s._v("对表级别进行设置：")])]),s._v(" "),t("p",[s._v("这些参数属于表的storage参数。通过ALTER TABLE .. SET STORAGE_PARAMETER可以进行个性化的设置。")]),s._v(" "),t("p",[s._v("autovacuum_vacuum_threshol，autovacuum_analyze_threshol")]),s._v(" "),t("p",[s._v("这两个参数分别确定要为 autovacuum 和 autoanalyzer 表中从上一次vacuum后更新或删除的记录数的最小数量。两者的默认值都是 50")]),s._v(" "),t("p",[s._v("autovacuum_vacuum_scale_factor")]),s._v(" "),t("p",[s._v("autovacuum_analyze_scale_factor")]),s._v(" "),t("p",[s._v("分别确定要为 autovacuum 和 autoanalyzer 安排的表需要更改的表的百分比")]),s._v(" "),t("p",[s._v("autovacuum_vacuum_scale_factor值为 0.2 (20%) 和autovacuum_analyze_scale_factor 0.1 (10%)。")]),s._v(" "),t("p",[s._v("针对大量行超级大表")]),s._v(" "),t("p",[s._v("vacuum threshold = autovacuum_vacuum_threshold + autovacuum_vacuum_scale_factor * n_live_tup")]),s._v(" "),t("p",[s._v("其中n_live_tup是活动元组的数量，这个值可以从pg_stat_all_tables视图获得。一旦死元组的数量达到了这个限额，那么就可以启动vacuum作业。")]),s._v(" "),t("h1",{attrs:{id:"_5、逻辑备份pg-dump"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5、逻辑备份pg-dump"}},[s._v("#")]),s._v(" 5、逻辑备份pg_dump")]),s._v(" "),t("p",[s._v("特点：")]),s._v(" "),t("p",[s._v("即使数据库正在被并发使用，它也能创建一致的备份。")]),s._v(" "),t("p",[s._v("不阻塞其他用户访问数据库（读取或写入）")]),s._v(" "),t("p",[s._v("只能备份单个数据库，不会导出角色和表空间相关的信息")]),s._v(" "),t("p",[s._v("生产环境建议方式")]),s._v(" "),t("p",[s._v("\\1. -F c 备份为二进制格式, 压缩存储. 并且可被pg_restore用于精细还原，输出输入 IO 比较稳定")]),s._v(" "),t("p",[s._v("二进制文件备份")]),s._v(" "),t("p",[s._v("\\1. pg_dump -F c -f /tmp/testdb.dmp -C -EUTF8 -h 127.0.0.1 -U postgres testdb")]),s._v(" "),t("p",[s._v("另外可以")]),s._v(" "),t("p",[s._v("\\1. 1）根据二进制备份文件生成toc文件")]),s._v(" "),t("p",[s._v("\\2. pg_restore -l -f /tmp/toc1 /tmp/testdb.dmp")]),s._v(" "),t("p",[s._v("\\3. 2）修改 toc文件，以首行加分号“；”的方式注释掉不用还原的内容")]),s._v(" "),t("p",[s._v("\\4. vi /tmp/toc1")]),s._v(" "),t("p",[s._v("\\5. 265; 1259 25280 TABLE public postgres_log postgres")]),s._v(" "),t("p",[s._v("\\6. 266; 1259 25293 TABLE public t2 postgres")]),s._v(" "),t("p",[s._v("并行处理")]),s._v(" "),t("p",[s._v("\\1. pg_dump -Fd -j4 -f /tmp/db.dir testdb #-F d 以目录的格式创建备份")]),s._v(" "),t("p",[s._v("\\2. pg_restore -d testdb3 -j4 /tmp/db.dir")]),s._v(" "),t("p",[s._v("\\3. -j 参数指定同时几个进程来同时执行，每个进程同时只处理一个表的数据。")]),s._v(" "),t("h1",{attrs:{id:"_6、优化方法论"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6、优化方法论"}},[s._v("#")]),s._v(" 6、优化方法论")]),s._v(" "),t("p",[s._v("了解需求，考虑将需求最小化，具备少做事的意识乃是顶级优化。")]),s._v(" "),t("h1",{attrs:{id:"_7、监控粒度信息"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_7、监控粒度信息"}},[s._v("#")]),s._v(" 7、监控粒度信息")]),s._v(" "),t("p",[s._v("最多的是DataFileWrite，其次是transactionid,再后面是DatafileRead和buffer_mapping。")]),s._v(" "),t("p",[s._v("DatafileWrite是等待想relation文件写入")]),s._v(" "),t("p",[s._v("DatafileRead是从relation文件读入")]),s._v(" "),t("p",[s._v("Transactionid是等待一个事务结束")]),s._v(" "),t("p",[s._v("Buffer_mapping是等待将数据块与缓冲池中的缓冲区。这些都是和Benchmark测试关联比较紧密的")]),s._v(" "),t("p",[s._v("Extend是等待relation文件扩展结束。这个等待居然比tuple还高")]),s._v(" "),t("p",[s._v("tuple是等待获取元组锁。")]),s._v(" "),t("h1",{attrs:{id:"_8、绑定变量的使用问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_8、绑定变量的使用问题"}},[s._v("#")]),s._v(" 8、绑定变量的使用问题")]),s._v(" "),t("p",[s._v("优点：让SQL可以共享，可以让一条类似的SQL在多次执行中共享查询执行计划")]),s._v(" "),t("p",[s._v("缺点：绑定变量的差异可能选择不同执行计划才好的问题在很多时候都是存在的")]),s._v(" "),t("h1",{attrs:{id:"_9、开启大页"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_9、开启大页"}},[s._v("#")]),s._v(" 9、开启大页")]),s._v(" "),t("p",[s._v("作用：降低系统内存占用")]),s._v(" "),t("p",[s._v("优势：")]),s._v(" "),t("p",[s._v("1、CPU的TLB可以缓存的物理地址空间更大，从而提升TLB的命中率，降低CPU负载；")]),s._v(" "),t("p",[s._v("2、Huge Page使用的内存是不可交换（swap）的，没有内存空间换入/换出的开销；")]),s._v(" "),t("p",[s._v("3、极大的减少了系统维护PageTable的内存开销。")]),s._v(" "),t("p",[s._v("劣势：")]),s._v(" "),t("p",[s._v("1、Huge Page使用的内存需要预先分配；")]),s._v(" "),t("p",[s._v("2、Huge Page使用固定大小的内存区域，不会被释放；")]),s._v(" "),t("p",[s._v("3、对于写密集型的场景，Huge Page会加大Cache写冲突的发生概率。")]),s._v(" "),t("p",[s._v("**使用场景：**不推荐PG实例开启Huge Page的场景：写业务密集，热点数据集中且内存使用较小。")]),s._v(" "),t("p",[s._v("计算大页脚本")]),s._v(" "),t("h1",{attrs:{id:"_10、快速加载sql入库的方法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_10、快速加载sql入库的方法"}},[s._v("#")]),s._v(" 10、快速加载sql入库的方法")]),s._v(" "),t("p",[s._v("查看自动提交是否关闭")]),s._v(" "),t("p",[s._v("\\echo :AUTOCOMMIT")]),s._v(" "),t("p",[s._v("关闭")]),s._v(" "),t("p",[s._v("\\set AUTOCOMMIT OFF")]),s._v(" "),t("p",[s._v("执行插入数据，在文件后加入commit;参数")]),s._v(" "),t("p",[s._v("\\i /var/lib/pgsql/testdb1.sql")]),s._v(" "),t("p",[s._v("以下是测试200w数据")]),s._v(" "),t("p",[s._v("只导出insert形式的数据（用copy导入会报错）")]),s._v(" "),t("p",[s._v('pg_dump -U postgres -d postgres -p 5432 --column-inserts -t "testdb1" > /var/lib/pgsql/testdb1.sql')]),s._v(" "),t("p",[s._v("只导出表结构")]),s._v(" "),t("p",[s._v('pg_dump -U postgres -d postgres -p 5432 -s -t "testdb1" > /var/lib/pgsql/testdb1_struct.sql')]),s._v(" "),t("p",[s._v("方案一：psql -f 导入，7分钟导入数据量")]),s._v(" "),t("p",[t("img",{attrs:{src:"/image/clip_/image002-16466159506211.jpg",alt:"img"}})]),s._v(" "),t("p",[s._v("方案二：\\set AUTOCOMMIT OFF，添加")]),s._v(" "),t("p",[s._v("导入，5分钟之内能弄完")]),s._v(" "),t("p",[s._v("方案三：开启事务")]),s._v(" "),t("p",[s._v("begin:")]),s._v(" "),t("p",[s._v("\\i 执行脚本")]),s._v(" "),t("p",[s._v("commit;")]),s._v(" "),t("p",[s._v("大页计算脚本和注意事项")]),s._v(" "),t("p",[s._v("#!/bin/bash  PGDATA='/pg13/pgdata'  pid="),t("code",[s._v("head -1 $PGDATA/postmaster.pid")]),s._v("  echo 'Pid: $pid'  peak="),t("code",[s._v("grep ^VmPeak /proc/$pid/status | awk '{ print $2 }'")]),s._v("  echo 'VmPeak: $peak kB'  hps="),t("code",[s._v("grep ^Hugepagesize /proc/meminfo | awk '{ print $2 }'")]),s._v("  echo 'Hugepagesize: $hps kB'  hp=$((peak/hps))  echo Set Huge Pages: $hp  sysctl -w vm.nr_hugepages=$hp  不要忘记将此设置添加到/etc/sysctl.conf，以便在重启后重新应用它。  echo 3170 > /proc/sys/vm/nr_hugepages  cat >> /etc/sysctl.conf <<'EOF'  vm.nr_hugepages=3170  EOF  sysctl -p  通过此脚本计算出大页的大小，然后添加到/etc/sysctl.conf里，sysctl -p生效。  参考连接：  https://baijiahao.baidu.com/s?id=1709212963361949625&wfr=spider&for=pc")]),s._v(" "),t("p",[s._v("有用知识点")]),s._v(" "),t("p",[t("a",{attrs:{href:"https://pgfans.cn/a/1634",target:"_blank",rel:"noopener noreferrer"}},[s._v("PG恢复被打了删除标记的列"),t("OutboundLink")],1)]),s._v(" "),t("p",[s._v("授权某个模式下所有的表和新增的表")]),s._v(" "),t("p",[t("img",{attrs:{src:"/image//image-20220329162624551.png",alt:"/image-20220329162624551"}})]),s._v(" "),t("h1",{attrs:{id:"_11、pg10分区表插入更新无法解决方法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_11、pg10分区表插入更新无法解决方法"}},[s._v("#")]),s._v(" 11、pg10分区表插入更新无法解决方法")]),s._v(" "),t("p",[s._v("方法1：建立函数")]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("create")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("or")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("replace")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("function")]),s._v(" f_upsert"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("integer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("character")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("timestamp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("returns")]),s._v(" void "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" $$  \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("declare")]),s._v("  \n  res "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("  \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("begin")]),s._v("  \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("update")]),s._v(" users "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" user_name"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("$"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("logdate"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("$"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" user_id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("$"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("  \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("not")]),s._v(" found "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("then")]),s._v("  \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("insert")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("into")]),s._v(" users "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("user_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("user_name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("logdate"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("$"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("$"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("$"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("  \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("  \n  exception "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("when")]),s._v(" others "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("then")]),s._v("  \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("  \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("  \n$$ "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("language")]),s._v(" plpgsql strict"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br")])]),t("p",[s._v("方法2：采用with的方式")]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" upsert "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("update")]),s._v(" users "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" user_name"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("$user_name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("logdate"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("$logdate "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" user_id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("$user_id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("returning")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("insert")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("into")]),s._v(" users "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" $user_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("$user_name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("$logdate "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("not")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("exists")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" upsert "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" user_id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("$user_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("    \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("insert")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("into")]),s._v(" test "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("info"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("crt_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("$"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("$"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("$"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" upsert "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("update")]),s._v(" users "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" user_name"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'DD'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("logdate"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2021-03-21'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" user_id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("returning")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("insert")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("into")]),s._v(" users "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("$user_name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("$logdate "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("not")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("exists")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" upsert "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" user_id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("$user_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("    \n\n\npostgres"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# select * from users;")]),s._v("\n user_id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" user_name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("        logdate         \n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("---------+-----------+------------------------")]),s._v("\n       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" AA        "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("17")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),s._v(":"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),s._v(":"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("05")]),s._v("\n       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" BB        "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("02")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),s._v(":"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),s._v(":"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("05")]),s._v("\n       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" CC        "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("03")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("19")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),s._v(":"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),s._v(":"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("04")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("rows")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\npostgres"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# select f_upsert(1,'2','2021-01-18');")]),s._v("\npostgres"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# select * from users;")]),s._v("\n user_id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" user_name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("        logdate         \n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("---------+-----------+------------------------")]),s._v("\n       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("         "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),s._v(":"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),s._v(":"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("05")]),s._v("\n       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" BB        "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("02")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),s._v(":"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),s._v(":"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("05")]),s._v("\n       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" CC        "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("03")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("19")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),s._v(":"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),s._v(":"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("00")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("04")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("rows")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br")])]),t("h1",{attrs:{id:"_12、postgresql中mvcc-表膨胀问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_12、postgresql中mvcc-表膨胀问题"}},[s._v("#")]),s._v(" 12、postgresql中mvcc_表膨胀问题")]),s._v(" "),t("p",[s._v("pg中的mvcc\n旧版本和新版本在同一个数据库的问题")]),s._v(" "),t("p",[s._v("行发生了修改就有新版本和旧版本，存在同样的数据文件里面，如果垃圾回收不及时，就会发生表膨胀")]),s._v(" "),t("p",[s._v("技术原理")]),s._v(" "),t("p",[s._v("存储旧版本：解决并发事务，方便查询旧的版本数据")]),s._v(" "),t("p",[s._v("影响范围，行业，业务")]),s._v(" "),t("p",[s._v("对于高频率的更新，插入，删除场景就会有问题")]),s._v(" "),t("p",[s._v("传感器，出租车位置，等更新多的场景，容易出问题，垃圾回收不及时，就会膨胀")]),s._v(" "),t("p",[s._v("什么时候回收不及时")]),s._v(" "),t("p",[s._v("看看有没有2pc")]),s._v(" "),t("p",[s._v("看看垃圾回收设置的内存是不是过小")]),s._v(" "),t("p",[s._v("垃圾回收工作进程太少了")]),s._v(" "),t("p",[s._v("磁盘性能")]),s._v(" "),t("p",[s._v("膨胀之后会有什么问题")]),s._v(" "),t("p",[s._v("1.存储空间不足")]),s._v(" "),t("p",[s._v("2.访问的时候io的范围会增加，本来访问一个数据块的现在需要访问2，3个数据块了")]),s._v(" "),t("p",[s._v("3.内存的消耗增加了，因为内存buffer要去缓存block")]),s._v(" "),t("p",[s._v("4.性能下降")]),s._v(" "),t("p",[s._v("解决：")]),s._v(" "),t("p",[s._v("设置参数\nhttps://blog.csdn.net/weixin_34360651/article/details/90504302")]),s._v(" "),t("p",[s._v("表膨胀解决方法")]),s._v(" "),t("p",[s._v("https://ctypyb2002.blog.csdn.net/article/details/82774684?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.control")]),s._v(" "),t("p",[s._v("新引入的问题")]),s._v(" "),t("p",[s._v("1、需要io延时更低的硬盘")]),s._v(" "),t("p",[s._v("2、牺牲了长事务")]),s._v(" "),t("p",[s._v("3、需要增加监控项")]),s._v(" "),t("p",[s._v("有没有希望解决这个坑 ：基于专门的回归段的存储引擎")]),s._v(" "),t("h1",{attrs:{id:"_13、postgresql避免oom方法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_13、postgresql避免oom方法"}},[s._v("#")]),s._v(" 13、postgresql避免oom方法")]),s._v(" "),t("p",[s._v("操作系统层：")]),s._v(" "),t("p",[s._v("vm.overcommit_memory设置为2：sysctl -w vm.overcommit_memory=2\n修改postgres进程的oom_score：echo -1000 > /proc/self/oom_score_adj")]),s._v(" "),t("p",[s._v("参考文章")]),s._v(" "),t("p",[s._v("https://weibo.com/ttarticle/p/show?id=2309404665709073662196&sudaref=www.baidu.com")]),s._v(" "),t("p",[s._v("https://cdn.modb.pro/db/43944")]),s._v(" "),t("h1",{attrs:{id:"_14、wal记录"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_14、wal记录"}},[s._v("#")]),s._v(" 14、wal记录")]),s._v(" "),t("p",[s._v("数据先到wal buffer--\x3e在落盘保证数据\nlsn不断放大的号，确保回放，把最新的lsn，从上一次检查点重放\n保证数据库不丢数据\n是如何恢复的\n重放xlog从磁盘到wal buffer ，redo poin它中有lsn号，去和shared buffer中的lsn做对比，大的就回放\n块折断\nfull_page_writes作用：是否开启全页写入，为了防止块折断（块损坏）的一种策略\n判断：checksum值\n采用机制：在checkponit后的一个块第一次变脏后就要整块写入到wal日志中，\n后续修改这个块，只要把修改信息写入到wal日志\n断电重启，有块折断，\n则在全页写入的块为基础进行恢复\n最后覆盖磁盘上的折断块\n参数checkpoint_segments对checkpoint影响\n作用：控制checkpoint的间隔\n过大：恢复时间会变长\t\n过小：造成频繁的checkpoint进而导致写入了过多的全页，可能wal日志暴增\n检查点作用\n1.将事务提交的修改写进disk（写脏数据）；保证数据库的完整性和一致性。\n2.缩短恢复时间,将脏页写入相应的数据文件,确保修改后的文件通过fsync()写入到磁盘。\n触发条件：\n1、checkpoint_timeout设置时间\n2、为checkpoint_segments设置的 WAL 段文件的数量自上一个检查点以来已经被消耗（默认3）\n3、WAL 段文件的总大小已超过参数max_wal_size的值（默认值为 1GB（64 个文件））\n4、PostgreSQL 服务器在smart或fast模式下停止\n5、手动执行CHECKPOINT\n6、写入WAL的数据量已达到参数max_wal_size（默认值：1GB）\n7、执行pg_start_backup函数时\n8、在进行数据库配置时")]),s._v(" "),t("p",[s._v("pg_control文件\n包含检查点的基本信息，如果损坏或无法读取，则无法启动恢复过程，从而无法获得起点。")]),s._v(" "),t("p",[s._v("WAL段切换\n1、wal段文件被写满\n2、函数pg_switch——wal()被调用\n3、启用了archive_mode,且已经超过archive_timeout配置的超时时间。\narchive_timeout时间短会导致空间膨胀")]),s._v(" "),t("h1",{attrs:{id:"_15、postgresql中lock-timeout设置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_15、postgresql中lock-timeout设置"}},[s._v("#")]),s._v(" 15、postgresql中lock_timeout设置")]),s._v(" "),t("p",[s._v("设置为10s")]),s._v(" "),t("p",[s._v("session1：测试插入更新数据")]),s._v(" "),t("p",[t("img",{attrs:{src:"/image//clip_/image002.jpg",alt:"img"}})]),s._v(" "),t("p",[s._v("session2:同时更新事务一中的数据，锁超时事务被杀掉")]),s._v(" "),t("p",[t("img",{attrs:{src:"/image//clip_/image004.jpg",alt:"img"}})]),s._v(" "),t("p",[s._v("继续在seasion2中操作会报错")]),s._v(" "),t("p",[t("img",{attrs:{src:"/image//clip_/image006.jpg",alt:"img"}})]),s._v(" "),t("p",[s._v("session2选择rollback或者commit")]),s._v(" "),t("p",[s._v("rollback回滚当前事务，commit提交报错之前执行的操作")]),s._v(" "),t("p",[s._v("session1执行commit提交成功；")]),s._v(" "),t("p",[t("img",{attrs:{src:"/image//clip_/image008.jpg",alt:"img"}})])])}),[],!1,null,null,null);t.default=r.exports}}]);